After the business logic processing, the upstream data became skewed or locally aggregated (most of the keys are concentrated in a single partition).
Since coalesce() does not perform a shuffle, it only merges existing partitions without redistributing the data, resulting in uneven file sizes and more localized data similarity.

The Snappy compression algorithm we are using is highly dependent on the local similarity of data.
Unlike repartition, which randomizes the data, coalesce preserves the natural distribution of the upstream data.
This means that in some Parquet files, consecutive column values are very similar, which significantly improves Snappy’s compression efficiency.

As a result, the overall file size decreases due to enhanced local compressibility and reduced metadata overhead — this is normal.
Therefore, a reduction in file size and count alone does not necessarily indicate data loss; the actual data content must be verified to confirm completeness.
