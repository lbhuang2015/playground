# LLM Configuration
# Options: openai, anthropic, google_vertexai, google_genai, etc.
LLM_PROVIDER=openai
# API Key for the selected provider. For Ollama, you can use any non-empty string like 'NA'.
OPENAI_API_KEY=your_api_key_here
# Model name (e.g., gpt-4o, claude-3-5-sonnet-latest, llama3)
MODEL_NAME=llama3
# Base URL for the LLM API. For local Ollama, typically http://localhost:11434/v1
OPENAI_API_BASE=http://localhost:11434/v1

# Spark Log Paths
# Full path to the Spark Event Log file (e.g., /path/to/application_123.log or /path/to/application_123.log.gz)
EVENT_LOG_PATH=/path/to/your/spark-event-log
# Full path to the Spark Driver Log file (e.g., /path/to/driver.log or /path/to/driver.log.lz4)
DRIVER_LOG_PATH=/path/to/your/spark-driver-log